# Seq2Seq
- 系列（sequence）を受け取り、別の系列へ変換するモデル
- 自然言語処理でよく利用される
- 圧縮するencoderと、出力を展開するdecoderからなる
- 以下は活用例
  - 機械翻訳
  - 文章要約
  - 対話

## 対話文の生成
- 大量の対話文コーパスを用意
- encoderに文章を入力すると、decoderから返事が出力されるように、Seq2Seqに学習させる
- 訓練では、ある時刻におけるdecoderの出力が、次の時刻の入力に近づくように学習を行う（教師強制）
- 訓練済みのモデルを使用する際は、ある時刻におけるdecoderの出力を次の時刻におけるdecoderの入力として扱う
